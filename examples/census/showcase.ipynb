{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cengine\n",
    "\n",
    "client = cengine.Client(username='hamza@maiot.io', \n",
    "                        password='password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conceptually, every provider configures where our pipelines are running and persisting artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUCKET_NAME ='gs://BUCKET_NAME'\n",
    "# SERVICE_ACCOUNT = '/SERVICE_ACCOUNT.json'\n",
    "# PROVIDER_NAME = 'PROVIDER_NAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_provider = client.create_provider(name=PROVIDER_NAME, \n",
    "#                                      provider_type='gcp', \n",
    "#                                      args={'service_account': SERVICE_ACCOUNT, \n",
    "#                                            'artifact_store': BUCKET_NAME})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the first provider on the list\n",
    "my_provider = client.get_providers()[0]\n",
    "\n",
    "print(my_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The concept of workspaces is created to maintain an organized and efficient structure within the ML workflow of your organization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a workspace\n",
    "# active_workspace = client.create_workspace(name=\"ShowcaseWorkspace\", \n",
    "                                           # provider_id=my_provider.id)\n",
    "# print(active_workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first workspace. Ensure this is the `HelloWorkspace`\n",
    "active_workspace = client.get_workspaces()[1]\n",
    "\n",
    "print(active_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasources are configurable, and fully versionable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_datasource = client.create_datasource(name='QuickstartDataset',\n",
    "#                                           provider_id=my_provider.id,\n",
    "#                                           source='bq',\n",
    "#                                           type='tabular', \n",
    "#                                           args={\"dataset\": \"ml_datasets\", \n",
    "#                                                 \"table\": \"census_adult_income\", \n",
    "#                                                 \"project\": \"bigquery-public-data\"})\n",
    "                                                \n",
    "# print(new_datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_datasource_commit = client.commit_datasource(new_datasource.id)\n",
    "\n",
    "# print(new_datasource_commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the specific datasource\n",
    "new_datasource = client.get_datasources()[1]\n",
    "# Get the version of the data we want\n",
    "new_datasource_commit = client.get_datasource_commits(new_datasource.id)[0]\n",
    "\n",
    "print(new_datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample = client.peek_datasource_commit(new_datasource.id, \n",
    "                                       new_datasource_commit.id)\n",
    "    \n",
    "pd.DataFrame(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines define an end-to-end training experiment from splitting to evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cengine import PipelineConfig\n",
    "\n",
    "# Start with a template\n",
    "c = PipelineConfig.from_datasource(client=client,\n",
    "                                   datasource_id=new_datasource.id,\n",
    "                                   commit_id=new_datasource_commit.id)\n",
    "\n",
    "# Configure you dataset split\n",
    "c.split.categorize.by = 'marital_status'  # group by marital status, to represent this equally in train/eval\n",
    "c.split.ratio = {'train': 0.8, 'eval': 0.2}\n",
    "\n",
    "# Each feature can undergo multuple, individual transforms\n",
    "# For now, we configure a non-default preprocessing with a built-in method\n",
    "c.features['education_num'].transform.add_methods(\n",
    "    {'method':'compute_and_apply_vocabulary'})\n",
    "    \n",
    "# Configure your labels\n",
    "del c.features.income_bracket\n",
    "c.labels.add(['income_bracket'])\n",
    "\n",
    "# Configure your evaluation\n",
    "del c.features.native_country\n",
    "c.evaluator.slices = [['native_country']]\n",
    "c.evaluator.metrics = ['binary_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can define arbitrary custom code here for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cengine import Method\n",
    "\n",
    "from transform import identity\n",
    "\n",
    "# Custom function\n",
    "c.features['hours_per_week'].transform.add_methods([Method.from_callable(client=client, \n",
    "                                                                         fn=identity,\n",
    "                                                                         params={'param_1': 2,\n",
    "                                                                                 'param_2': 'temp'})])\n",
    "\n",
    "print(c.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our model function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your training with your model\n",
    "from cengine import Trainer\n",
    "from model import custom_model\n",
    "\n",
    "c.trainer = Trainer.from_callable(client=client, \n",
    "                                  fn=custom_model,\n",
    "                                  params={'input_units': 13,\n",
    "                                          'output_units': 1,\n",
    "                                          'batch_size': 16,\n",
    "                                          'loss': 'binary_crossentropy',\n",
    "                                          'metrics': ['binary_accuracy'],\n",
    "                                          'lr': 0.0005,\n",
    "                                          'epochs': 10})\n",
    "\n",
    "print(c.trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An immutable artifact that lets you reproduce precisely this experiment\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register and train a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pipeline = client.push_pipeline(name='census_run_01',\n",
    "                                      config=c,\n",
    "                                      workspace_id=active_workspace.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "first_pipeline_run = client.train_pipeline(pipeline_id=first_pipeline.id,\n",
    "                                           datasource_commit_id=new_datasource_commit.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the above takes a few minutes, lets explore the options we have in the train_pipeline method\n",
    "\n",
    "client.train_pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check pipeline status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wait here until STATUS turns to 'SUCCEEEDED'\n",
    "\n",
    "client.get_pipeline_status(workspace_id=active_workspace.id)[first_pipeline.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.get_pipeline_run_logs(pipeline_id=first_pipeline.id, \n",
    "                             pipeline_run_id=first_pipeline_run.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Execute twice if it does not appear the first time\n",
    "client.get_statistics(pipeline_id=first_pipeline.id,\n",
    "                      pipeline_run_id=first_pipeline_run.id,\n",
    "                      magic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The evaluator key had let us define metrics and slices. Now we can see the results across our 'native_country' slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Execute slicing graphic twice if it does not appear the first time\n",
    "# Note: Change slicing_column to native_country in the slicing code block\n",
    "\n",
    "client.evaluate_single_pipeline(pipeline_id=first_pipeline.id,\n",
    "                                pipeline_run_id=first_pipeline_run.id,\n",
    "                                magic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the model: You can extract the model to deploy it on your own or deploy it automatically on a serving_backend and logic of your choice. We take the former approach here and download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to delete the 'model' directory before executing\n",
    "\n",
    "import os \n",
    "\n",
    "client.download_model(pipeline_id=first_pipeline.id, \n",
    "                      pipeline_run_id=first_pipeline_run.id,\n",
    "                      output_path=os.path.join(os.getcwd(), 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate: Now comes the most powerful aspect of all this. Not only is this experiment fully persisted forever, anyone in the team #### can now pull this experiment pipeline and improve and compare results. All interim results are cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_config = client.pull_pipeline(pipeline_id=first_pipeline.id)\n",
    "\n",
    "# Lets double the batch size\n",
    "second_config.trainer.params['batch_size'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pipeline = client.push_pipeline(name='census_run_02',\n",
    "                                       config=second_config,\n",
    "                                       workspace_id=active_workspace.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pipeline_run = client.train_pipeline(\n",
    "    pipeline_id=second_pipeline.id,\n",
    "    datasource_commit_id=new_datasource_commit.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait here until STATUS turns to 'SUCCEEEDED'\n",
    "\n",
    "client.get_pipeline_status(workspace_id=active_workspace.id)[second_pipeline.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate the second pipeline to see how we did by increasing batch size\n",
    "\n",
    "# Note: Execute slicing graphic twice if it does not appear the first time\n",
    "client.evaluate_single_pipeline(pipeline_id=second_pipeline.id,\n",
    "                                pipeline_run_id=second_pipeline_run.id,\n",
    "                                magic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare multiple pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.compare_multiple_pipelines(active_workspace.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
